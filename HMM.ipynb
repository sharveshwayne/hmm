{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import brown\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency function \n",
    "def fre(x):\n",
    "    from collections import Counter\n",
    "    types =  Counter(tuple(x) for x in x )\n",
    "    #print(types)\n",
    "\n",
    "    # storing it as a list \n",
    "    freq = []\n",
    "    for value in types.items() :\n",
    "        freq.append(value)\n",
    "\n",
    "    #sorting the list in decending order\n",
    "    def sortthird(freq): \n",
    "        return freq[1] \n",
    "    freq.sort(key = sortthird ,reverse = True) \n",
    "    #print(freq)\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert start \"<s>\" and end \"<\\s>\" symbols for each sentence \n",
    "p = brown.tagged_sents()\n",
    "brown_corpus = []\n",
    "for i in p :\n",
    "    i.insert(0,('<s>','<s>'))\n",
    "    i.insert(len(i),('<\\s>','<\\s>'))\n",
    "    brown_corpus.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating test and training sets from the brown corpus\n",
    "# test set contains first 100 sentences\n",
    "brown_test = []\n",
    "brown_train = []\n",
    "sen = 0\n",
    "for i in brown_corpus:\n",
    "    sen += 1\n",
    "    if sen <= 10:\n",
    "        brown_test.append(i)\n",
    "    else:\n",
    "        brown_train.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting training set to a [word,tag] sequence\n",
    "brown_words_tag = []\n",
    "for i in brown_train:\n",
    "    for j in i:\n",
    "        brown_words_tag.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency of each [word,tag] \n",
    "fre_wordtag = fre(brown_words_tag)\n",
    "#print(fre_wordtag)\n",
    "\n",
    "#frerquency of ti (just the tags) \n",
    "brown_tag = []\n",
    "for i in brown_train:\n",
    "    for j in i:\n",
    "         brown_tag.append(j[1])\n",
    "\n",
    "# getting frequencies of each tag in brown_tag\n",
    "types =  collections.Counter(brown_tag)\n",
    "fre_tag = []\n",
    "for value in types.items() :\n",
    "    fre_tag.append(value)\n",
    "    \n",
    "#sorting the list in decending order\n",
    "def sortthird(fre_tag): \n",
    "    return fre_tag[1] \n",
    "fre_tag.sort(key = sortthird ,reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probabitity of p(wi|ti)\n",
    "probWiti = []\n",
    "list1 =[]\n",
    "list2 = []\n",
    "list3 = []\n",
    "for i in fre_wordtag:\n",
    "    for j in fre_tag:\n",
    "        if i[0][1] == j[0]:\n",
    "            temp = [i[0] , i[1]/j[1]]\n",
    "            probWiti.append(temp)\n",
    "            list1.append(i[0][0])\n",
    "            temp1 = [i[0][1], i[1]/j[1]]\n",
    "            list2.append(temp1)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "#probability of p{ti|t(i-1)}\n",
    "\n",
    "\n",
    "#frequency of [ti,t(i-1)]             #Step 1\n",
    "bi_tag = []\n",
    "x = len(brown_words_tag)\n",
    "for j in range(x):\n",
    "    if j+1 < x:  \n",
    "        temp = [brown_words_tag[j][1] , brown_words_tag[j+1][1]]\n",
    "        if temp != ['<\\s>' ,'<s>' ]:\n",
    "            bi_tag.append(temp)\n",
    "\n",
    "fre_bi_tag= fre(bi_tag)   #Step 2\n",
    "\n",
    "# probabitity\n",
    "probbitag = []             #Step 3\n",
    "for i in fre_bi_tag:\n",
    "    for j in fre_tag:\n",
    "        if i[0][0] == j[0]:\n",
    "            temp = [i[0] , i[1]/j[1]]\n",
    "            probbitag.append(temp)          \n",
    "\n",
    "pos_tag = [] \n",
    "for i in fre_tag:\n",
    "    pos_tag.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vitervi algorithm\n",
    "\n",
    "# creating lattice of transition and emissions probability\n",
    "\n",
    "#emission probability for a sentence\n",
    "l = len(sentence)\n",
    "c = 1\n",
    "sentence = brown_test[4]    # change the sentence by replacing [i] to try out different sentences from brown_test; i={0,10}\n",
    "lattic_emission = [[] for i in range(l)]  # emission probability lattice\n",
    "sen_tag = []                              # set of all different tags the sentence could have\n",
    "for i in range(l):\n",
    "    for j in probWiti:\n",
    "        if sentence[i][0] == j[0][0]: \n",
    "            lattic_emission[i].append(j) # lattice will only have element whose emission probability > 0, since for 0 emission probability, the final probability becomes zero\n",
    "            if j[0][1] not in sen_tag:\n",
    "                sen_tag.append(j[0][1]) # set of all posible tags the sentence could have\n",
    "    if(len(lattic_emission[i])== 0):    # for unknown words in sentence \n",
    "        temp = [(sentence[i][0], 'NN') , 0.11 ] # 'unk' tags are assumed to be 'NN' since they are the most occuring tags with a 11% probability \n",
    "        lattic_emission[i].append(temp)\n",
    "                \n",
    "       \n",
    "            \n",
    "#transition tags for this sentence\n",
    "l = len(sen_tag) \n",
    "tran_tag = []\n",
    "for i in sen_tag:\n",
    "    for j in sen_tag:\n",
    "        temp = (i , j)\n",
    "        if temp not in tran_tag: # avoid repetitions \n",
    "            tran_tag.append(temp)\n",
    "            \n",
    "\n",
    "            \n",
    "#transition probability for this sentence\n",
    "tran_pro = []\n",
    "for i in tran_tag:\n",
    "    for j in probbitag:\n",
    "        if i == j[0]:  \n",
    "            tran_pro.append(j) # the tag pairs not in probbitag have zero probability. Again, we are not considering them since result for such sentence will have 0 probability\n",
    "mat = []\n",
    "for i in lattic_emission:\n",
    "    temp = [i[0][0][0], len(i)]\n",
    "    mat.append(temp)       \n",
    "\n",
    "max_emission = []\n",
    "sequence = []\n",
    "for i in lattic_emission:\n",
    "    def sortthird(i): \n",
    "        return i[1] \n",
    "    i.sort(key = sortthird ,reverse = True) # getting maximum emission probability after each step\n",
    "    max_emission.append(i)\n",
    "l = len(mat)\n",
    "vi = []\n",
    "for i in range(l-1):\n",
    "    if i < l:\n",
    "        temp =(max_emission[i][0][0][1],max_emission[i+1][0][0][1])\n",
    "        vi.append(temp)\n",
    "        sequence.append(max_emission[i][0][0])\n",
    "temp = ('<\\s>', '<\\s>')\n",
    "sequence.append(temp)\n",
    "l = len(vi)\n",
    "Vj = [] #argmax from multiplication of transition and emission probabilities \n",
    "m = 0\n",
    "for i in range(l):\n",
    "    for j in tran_pro:\n",
    "        m += 1\n",
    "        if vi[i] == j[0]:\n",
    "            temp = max_emission[i][0][1]*j[1]\n",
    "            Vj.append(temp)\n",
    "            temp1= [max_emission[i][0][0],j[0]]\n",
    "    temp1= [max_emission[i][0][0],j[0]]\n",
    "    if(temp1 not in sequence):\n",
    "        temp1= [max_emission[i][0][0],j[0]]\n",
    "        \n",
    "def viterbi(Vj) : \n",
    "    result = 1\n",
    "    for x in Vj: \n",
    "         result = result * x  \n",
    "    return result         \n",
    "Viterbi = viterbi(Vj)\n",
    "print(sequence , '\\n' ,Viterbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy \n",
    "l = len(sentence)\n",
    "count = 0\n",
    "for i in range(l):\n",
    "    if sentence[i] == sequence[i]:\n",
    "        count +=1\n",
    "accuracy = (count / len(sentence))*100\n",
    "print(\"accuracy of HMM tagger for given sentence is \")\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
